# Video Content

The video content for the course can be found as part of multiple playlists from the channel [Artificial Whiteboard](https://www.youtube.com/channel/UCIslxZbyug9pRg00plukOCA) under the playlist [TensorFlow Developer Certificate](https://www.youtube.com/playlist?list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE).

## [Course Outline (5:21)](https://www.youtube.com/watch?v=D1kAy-pkNp4&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=1)    

## [00 - Deep Learning and TensorFlow Fundamentals](https://www.youtube.com/watch?v=YdqgT0IicIw&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=2)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 00.01 - What is deep learning? (4.38)    
00:04:38 - 00.02 - Why use deep learning? (9.38)    
00:14:17 - 00.03 - What are neural networks? (10.26)    
00:24:43 - 00.04 - What is deep learning already being used for? (8.36)    
00:33:21 - 00.05 - What is, and why use TensorFlow? (7.56)    
00:41:18 - 00.06 - What is a Tensor? (3.37)    
00:44:56 - 00.07 - What we're going to cover throughout the course (4.29)    
00:49:26 - 00.08 - How to approach this course (5.33)    
00:55:00 - 00.09 - Creating your first tensors with TensorFlow and tf.constant() (18.45)    
01:13:46 - 00.10 - Creating tensors with TensorFlow and tf.Variable() (7.07)    
01:20:54 - 00.11 - Creating random tensors with TensorFlow (9.40)    
01:30:35 - 00.12 - Shuffling the order of tensors (9.40)    
01:40:16 - 00.13 - Creating tensors from NumPy arrays (11.55)    
01:52:12 - 00.14 - Getting information from your tensors (tensor attributes) (11.57)    
02:04:10 - 00.15 - Indexing and expanding tensors (12.33)    
02:16:44 - 00.16 - Manipulating tensors with basic operations (5.34)    
02:22:19 - 00.17 - Matrix multiplication with tensors - Part 1 (11.53)    
02:34:14 - 00.18 - Matrix multiplication with tensors - Part 2 (13.29)    
02:47:44 - 00.19 - Matrix multiplication with tensors - Part 3 (10.03)    
02:57:47 - 00.20 - Changing the datatype of tensors (6.55)    
03:04:44 - 00.21 - Tensor aggregation (finding the min, max, mean & more) (9.49)    
03:14:13 - 00.22 - Tensor troubleshooting example (updating tensor data types) (6.13)    
03:20:47 - 00.23 - Finding the positional minimum and maximum of a tensor (argmin and argmax) (9.31)    
03:30:19 - 00.24 - Squeezing a tensor (removing all 1-dimension axes) (2.59)    
03:33:19 - 00.25 - One-hot encoding tensors (5.46)    
03:39:06 - 00.26 - Trying out more tensor math operations (4.47)    
03:43:54 - 00.27 - Exploring TensorFlow and NumPy's compatibility (5.43)    
03:49:37 - 00.28 - Making sure our tensor operations run really fast on GPUs (10.19)    

## [01 - Neural Network Regression with TensorFlow](https://www.youtube.com/watch?v=jLDq7yeLVQ0&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=3)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 01.01 - Introduction to Neural Network Regression with TensorFlow (7.33)    
00:07:34 - 01.02 - Inputs and outputs of a neural network regression model (8.59)    
00:16:33 - 01.03 - Anatomy and architecture of a neural network regression model (7.55)    
00:24:28 - 01.04 - Creating sample regression data (so we can model it) (12.46)    
00:37:16 - 01.05 - The major steps in modelling with TensorFlow (20.16)    
00:57:33 - 01.06 - Steps in improving a model with TensorFlow - Part 1 (6.02)    
00:07:34 - 01.07 - Steps in improving a model with TensorFlow - Part 2 (9.25)    
01:03:36 - 01.08 - Steps in improving a model with TensorFlow - Part 3 (12.33)    
01:13:02 - 01.09 - Evaluating a TensorFlow model - Part 1 ("visualize, visualize, visualize") (7.24)    
01:25:36 - 01.10 - Evaluating a TensorFlow model - Part 2 (the three datasets) (11.01)    
01:33:00 - 01.11 - Evaluating a TensorFlow model - Part 3 (getting a model summary) (17.18)    
01:44:03 - 01.12 - Evaluating a TensorFlow model - Part 4 (visualizing a model's layers) (7.14)    
02:01:23 - 01.13 - Evaluating a TensorFlow model - Part 5 (visualizing a model's predictions) (9.16)    
02:08:38 - 01.14 - Evaluating a TensorFlow model - Part 6 (common regression evaluation metrics) (8.05)    
02:17:55 - 01.15 - Evaluating a TensorFlow regression model - Part 7 (mean absolute error) (5.52)    
02:26:00 - 01.16 - Evaluating a TensorFlow regression model - Part 8 (mean square error) (3.18)    
02:31:54 - 01.17 - Setting up TensorFlow modelling experiments - Part 1 (start with a simple model) (13.50)    
02:49:04 - 01.18 - Setting up TensorFlow modelling experiments - Part 2 (increasing complexity) (11.29)    
03:00:36 - 01.19 - Comparing and tracking your TensorFlow modelling experiments (10.20)    
03:10:55 - 01.20 - How to save a TensorFlow model (8.19)    
03:19:16 - 01.21 - How to load and use a saved TensorFlow model (10.15)    
03:29:32 - 01.22 - (Optional) How to save and download files from Google Colab (6.18)    
03:35:51 - 01.23 - Putting together what we've learned - Part 1 (preparing a dataset) (13.31)    
03:49:23 - 01.24 - Putting together what we've learned - Part 2 (building a regression model) (13.20)    
04:02:45 - 01.25 - Putting together what we've learned - Part 3 (improving our regression model) (15.47)    
04:18:33 - 01.26 - Preprocessing data with feature scaling - Part 1 (what is feature scaling?) (9.34)    
04:28:08 - 01.27 - Preprocessing data with feature scaling - Part 2 (normalizing our data) (10.57)    
04:39:05 - 01.28 - Preprocessing data with feature scaling - Part 3 (fitting a model on scaled data) (7.40)    

## [02 - Neural Network Classification in TensorFlow](https://www.youtube.com/watch?v=aTw053kfu5Q&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=4)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 02.01 - Introduction to neural network classification in TensorFlow (8.25)    
00:08:26 - 02.02 - Example classification problems (and their inputs and outputs) (6.38)    
00:15:04 - 02.03 - Input and output tensors of classification problems (6.21)    
00:021:26 - 02.04 - Typical architecture of neural network classification models with TensorFlow (9.36)    
00:31:03 - 02.05 - Creating and viewing classification data to model (11.34)    
00:42:38 - 02.06 - Checking the input and output shapes of our classification data (4.38)    
00:47:16 - 02.07 - Building a not very good classification model with TensorFlow (12.10)    
00:59:28 - 02.08 - Trying to improve our not very good classification model (9.13)    
01:08:42 - 02.09 - Creating a function to view our model's not so good predictions (15.08)    
01:23:51 - 02.10 - Make our poor classification model work for a regression dataset (24.36)    
01:36:10 - 02.11 - Non-linearity - Part 1 (Straight lines and non-straight lines) (9.38)    
01:45:50 - 02.12 - Non-linearity - Part 2 (Building our first neural network with non-linearity) (5.47)    
01:51:38 - 02.13 - Non-linearity - Part 3 (Upgrading our non-linear model with more layers) (10.18)    
02:01:57 - 02.14 - Non-linearity - Part 4 (Modelling our non-linear data once and for all) (8.37)    
02:10:35 - 02.15 - Non-linearity - Part 5 (Replicating non-linear activation functions from scratch) (14.26)    
02:25:03 - 02.16 - Getting great results in less time by tweaking the learning rate (14.47)    
02:39:51 - 02.17 - Using the TensorFlow History object to plot a model's loss curves (6.11)    
02:46:04 - 02.18 - Using callbacks to find a model's ideal learning rate (17.32)    
03:03:37 - 02.19 - Training and evaluating a model with an ideal learning rate (9.20)    
03:12:58 - 02.20 - Introducing more classification evaluation methods (6.04)    
03:19:03 - 02.21 - Finding the accuracy of our classification model (4.17)    
03:23:21 - 02.22 - Creating our first confusion matrix (to see where our model is getting confused) (8.27)    
03:31:50 - 02.23 - Making our confusion matrix prettier (14.00)    
03:45:51 - 02.24 - Multi-class classification - Part 1 (Getting the data) (10.37)    
03:56:29 - 02.25 - Multi-class classification - Part 2 (Becoming one with the data) (7.07)    
04:03:38 - 02.26 - Multi-class classification - Part 3 (Building a multi-class classification model) (15.38)    
04:19:17 - 02.27 - Multi-class classification - Part 4 (Improving performance with normalization) (12.43)    
04:32:01 - 02.28 - Multi-class classification - Part 5 (Comparing normalized and non-normalised data) (4.13)    
04:36:15 - 02.29 - Multi-class classification - Part 6 (Finding the ideal learning rate) (10.38)    
04:46:54 - 02.30 - Multi-class classification - Part 7 (Evaluating our model) (13.16)    
05:00:11 - 02.31 - Multi-class classification - Part 8 (Creating a confusion matrix) (4.26)    
05:04:38 - 02.32 - Multi-class classification - Part 9 (Visualizing random model predictions) (10.42)    
05:15:20 - 02.33 - What "patterns" is our model learning? (15.33)    

## [03 - Computer Vision and Convolutional Neural Networks in TensorFlow](https://www.youtube.com/watch?v=i-P3w7QDN-8&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=5)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 03.01 - Introduction to Computer Vision with TensorFlow (9.36)    
00:09:36 - 03.02 - Introduction to Convolutional Neural Networks (CNNs) with TensorFlow (7.59)    
00:17:36 - 03.03 - Downloading an image dataset for our first Food Vision model (8.27)    
00:26:04 - 03.04 - Becoming One With Data - Part 1 (Inspecting the File paths) (5.05)    
00:31:10 - 03.05 - Becoming One With Data - Part 2 (12.26)    
00:43:37 - 03.06 - Becoming One With Data - Part 3 (4.22)    
00:48:00 - 03.07 - Building an end to end CNN Model (18.17)    
01:06:19 - 03.08 - Using a GPU to run our CNN model 5x faster (9.17)    
01:15:36 - 03.09 - Trying a non-CNN model on our image data (8.51)    
01:24:28 - 03.10 - Improving our non-CNN model by adding more layers (9.52)    
01:34:21 - 03.11 - Breaking our CNN model down - Part 1 (Becoming one with the data) (9.03)    
01:43:25 - 03.12 - Breaking our CNN model down - Part 2 (Preparing to load our data) (11.46)    
01:55:12 - 03.13 - Breaking our CNN model down - Part 3 (Loading our data with ImageDataGenerator) (9.54)    
02:05:07 - 03.14 - Breaking our CNN model down - Part 4 (Building a baseline CNN model (8.02)    
02:13:10 - 03.15 - Breaking our CNN model down - Part 5 (Looking inside a Conv2D layer) (15.20)    
02:28:32 - 03.16 - Breaking our CNN model down - Part 6 (Compiling and fitting our baseline CNN) (7.14)    
02:35:47 - 03.17 - Breaking our CNN model down - Part 7 (Evaluating our CNN's training curves) (11.45)    
02:47:33 - 03.18 - Breaking our CNN model down - Part 8 (Reducing overfitting with Max Pooling) (13.40)    
03:01:14 - 03.19 - Breaking our CNN model down - Part 9 (Reducing overfitting with data augmentation) (6.52)    
03:08:06 - 03.20 - Breaking our CNN model down - Part 10 (Visualizing our augmented data) (15.04)    
03:23:11 - 03.21 - Breaking our CNN model down - Part 11 (Training a CNN model on augmented data) (8.49)    
03:32:01 - 03.22 - Breaking our CNN model down - Part 12 (Discovering the power of shuffling data) (10.01)    
03:42:03 - 03.23 - Breaking our CNN model down - Part 13 (Exploring options to improve our model) (5.21)    
03:47:26 - 03.24 - Downloading a custom image to make predictions on (4.54)    
03:52:20 - 03.25 - Writing a helper function to load and preprocessing custom images (10.00)    
04:02:22 - 03.26 - Making a prediction on a custom image with our trained CNN (10.08)    
04:12:31 - 03.27 - Multi-class CNN's - Part 1 (Becoming one with the data) (14.59)    
04:27:31 - 03.28 - Multi-class CNN's - Part 2 (Preparing our data, turning it into tensors) (6.38)    
04:34:10 - 03.29 - Multi-class CNN's - Part 3 (Building a multi-class CNN model) (7.24)    
04:41:35 - 03.30 - Multi-class CNN's - Part 4 (Fitting a multi-class CNN model to the data) (6.02)    
04:47:38 - 03.31 - Multi-class CNN's - Part 5 (Evaluating our multi-class CNN model) (4.51)    
04:52:30 - 03.32 - Multi-class CNN's - Part 6 (Trying to fix overfitting by removing layers) (12.19)    
05:04:50 - 03.33 - Multi-class CNN's - Part 7 (Trying to fix overfitting with data augmentation) (11.45)    
05:16:37 - 03.34 - Multi-class CNN's - Part 8 (Things you could do to improve your CNN model) (4.23)    
05:21:01 - 03.35 - Multi-class CNN's - Part 9 (Making predictions with our model on custom images) (9.22)    
05:30:24 - 03.36 - Saving and loading our trained CNN model (6.21)    

## [04 - Transfer Learning in TensorFlow - Part 1 :: Feature Extraction](https://www.youtube.com/watch?v=E799buwqA-k&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=6)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 04.01 - What is and, why use transfer learning? (10.12)    
00:10:13 - 04.02 - Downloading and preparing data for our first transfer learning model (14.39)    
00:24:53 - 04.03 - Introducing Callbacks in TensorFlow and making a callback to track our models (10.01)    
00:34:55 - 04.04 - Exploring the TensorFlow Hub website for pretrained models (9.51)    
00:44:47 - 04.05 - Building and compiling a TensorFlow Hub feature extraction model (14.00)    
00:58:48 - 04.06 - Blowing our previous models out of the water with transfer learning (9.13)    
01:08:02 - 04.07 - Plotting the loss curves of our ResNet feature extraction model (7.35)    
01:15:38 - 04.08 - Building and training a pretrained EfficientNet model on our data (9.42)    
01:25:21 - 04.09 - Different Types of Transfer Learning (11.40)    
01:37:02 - 04.10 - Comparing Our Model's Results (15.16)    

## [05 - Transfer Learning in TensorFlow - Part 2 :: Fine-Tuning](https://www.youtube.com/watch?v=biAIFUL7UuQ&list=PLcPS3izl8N5sxZa7Ceu4tv8Y7P4TG_mXE&index=7)

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬
00:00:00 - 05.01 - Introduction to Transfer Learning in TensorFlow - Part 2 (Fine-Tuning) (6.16)    
00:06:16 - 05.02 - Importing a script full of helper functions (and saving lots of space) (7.35)    
00:13:52 - 05.03 - (Excercise) Imposter Syndrome (2.55)    
00:16:48 - 05.04 - Downloading and turning our images into a TensorFlow BatchDataset (15.38)    
00:32:28 - 05.05 - Discussing the four (actually five) modelling experiments we're running (2.15)    
00:34:43 - 05.06 - Comparing the TensorFlow Keras Sequential API versus the Functional API (2.34)    
00:37:17 - 05.07 - Creating our first model with the TensorFlow Keras Functional API (11.38)    
00:48:57 - 05.08 - Compiling and fitting our first Functional API model (10.53)    
00:59:51 - 05.09 - Getting a feature vector from our trained model (13.39)    
01:13:31 - 05.10 - Drilling into the concept of a feature vector (a learned representation) (3.43)    
01:17:15 - 05.11 - Downloading and preparing the data for Model 1 (1 percent of training data) (9.51)    
01:27:07 - 05.12 - Building a data augmentation layer to use inside our model (12.06)    
01:39:14 - 05.13 - Visualizing what happens when images pass through our data augmentation layer (10.56)    
01:50:10 - 05.14 - Building Model 1 (with a data augmentation layer and 1% of training data) (15.55)    
02:06:06 - 05.15 - Building Model 2 (with a data augmentation layer and 10% of training data) (16.37)    
02:22:45 - 05.16 - Creating a ModelCheckpoint to save our model's weights during training (7.25)    
02:30:10 - 05.17 - Fitting and evaluating Model 2 (and saving its weights using ModelCheckpoint) (7.14)    
02:37:25 - 05.18 - Loading and comparing saved weights to our existing trained Model 2 (7.17)    
02:44:43 - 05.19 - Preparing Model 3 (our first fine-tuned model) (20.26)    
03:05:11 - 05.20 - Fitting and evaluating Model 3 (our first fine-tuned model) (7.45)    
03:12:57 - 05.21 - Comparing our model's results before and after fine-tuning (10.26)    
03:23:25 - 05.22 - Downloading and preparing data for our biggest experiment yet (Model 4) (6.24)    
03:29:50 - 05.23 - Preparing our final modelling experiment (Model 4) (12.00)    
03:41:51 - 05.24 - Fine-tuning Model 4 on 100% of the training data and evaluating its results (10.19)    
03:52:11 - 05.25 - Comparing our modelling experiment results in TensorBoard (10.46)    
04:02:58 - 05.26 - How to view and delete previous TensorBoard experiments (2.04)    

## 06 - Transfer Learning in TensorFlow - Part 2 :: Scaling Up

▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬ Chapters ▬▬▬▬▬▬▬▬▬▬▬▬▬▬▬

06.01 - Introduction to Transfer Learning - Part 3 (Scaling Up) (6:19)


